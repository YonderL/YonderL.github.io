---
title: "INR-ECGAN: An Enhanced Conditional GAN with Implicit Neural Representation for SAR-to-Optical Image Translation"
collection: publications
category: conferences
permalink: /publication/2024-02-13-paper-title-number-4
date: 2024-02-13
venue: 'China Automation Congress (CAC)'
paperurl: 'http://Yonderl.github.io/files/INR-ECGAN.pdf'
bibtexurl: 'http://Yonderl.github.io/files/INR-ECGAN.bib'
citation: 'C. Feng, Y. Liu, N. Wang, Z. Chen, X. Wei and H. Liu, "INR-ECGAN: An Enhanced Conditional GAN with Implicit Neural Representation for SAR-to-Optical Image Translation," 2024 China Automation Congress (CAC)'
---

The SAR-to-Optical image translation task helps solve the interpretability of SAR images and has attracted much attention from researchers in recent years. Although existing methods based on conditional generative adversarial network (CGAN) have shown appealing potential for this task, the optical images generated by them still suffer from blurred details and color distortion. To this end, a novel enhanced CGAN with implic-it neural representation (INR-ECGAN) is proposed in this paper. Specifically, the proposed method utilizes convolutional residual blocks to encode the semantic features of SAR images at multiple scales. Then, a pyramid pooling module is employed to mine the global information of deep semantic features. Subsequently, an implicit decoder is designed to fuse the multi-scale semantic and global features and estimate a continuous function mapping from the fused features to the optical images. Finally, a discriminator that can simultaneously distinguish the generated and real optical images at multiple scales is adopted to improve the translation performance. Extensive experiments on public datasets have demonstrated the superiority of INR-ECGAN. The code will be available at https://github.com/YonderL/INR-ECGAN.
